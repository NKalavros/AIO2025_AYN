{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5369cfdf-84e2-4e4f-9b6e-499075609184",
   "metadata": {},
   "source": [
    "# RNA2Sig classifier\n",
    "\n",
    "Here we aim to classify the presence or absence of signatures in a sample given gene expression and one-hot encoded cancer type. Important notes:\n",
    "\n",
    "* Gene expression is taken from TCGA, normalized by mean-centering across the pan-gyn cohort.\n",
    "* We test two sets of genes:\n",
    "    * The top 1000 highly variable genes from the C6 gene set from MSigDB (`c6_top1000`)\n",
    "    * The L1000 landmark genes (`l1000`)\n",
    "* We filter signatures to those with <1000 zero values to ensure that each is well-represented across the pan-gyn cohort.\n",
    "* We remove signatures marked as sequencing artefacts according to COSMIC.\n",
    "* We keep signatures with unknown aetiology according to COSMIC.\n",
    "* For all signatures with exposure > 0, we assign it to 1 (signature is present). Otherwise, we assign it to 0 (signature is absent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7806ef-cdf5-453f-9a5d-4736d63a9506",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a053f356-a82e-4b4d-b0b6-ff29c03a2401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-038jb2_4 because the default path (/gpfs/home/yb2612/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed...\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing modules...\")\n",
    "\n",
    "# Core libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Numerical & data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    multilabel_confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Setting seed...\")\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  # python random seed\n",
    "    np.random.seed(seed)  # numpy random seed\n",
    "\n",
    "seed = 9\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea8a40-155e-429d-89b0-e65cbd0c796c",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0cfe4-2e64-417c-b79d-51c5867735db",
   "metadata": {},
   "source": [
    "## Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55722713-925e-4f2d-8b50-bbe2f97d0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_multilabel(model_name, X_train, y_train, kfold=True, n_folds=5, n_jobs=-1, params_dict=None, print_params=True, seed=9):\n",
    "    print()\n",
    "    print(f\"Training MultiOutputClassifier (XGBClassifier) on {model_name}...\")\n",
    "    print()\n",
    "\n",
    "    if params_dict is None:\n",
    "        params_dict = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"random_state\": seed,\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"device\":\"cuda\"\n",
    "        }\n",
    "\n",
    "    base_model = xgb.XGBClassifier(**params_dict)\n",
    "    multi_model = MultiOutputClassifier(base_model, n_jobs=n_jobs)\n",
    "\n",
    "    if print_params:\n",
    "        print(f\"{model_name} parameters:\")\n",
    "        print(json.dumps(base_model.get_params(), indent=2))\n",
    "\n",
    "    if kfold:\n",
    "        print(f\"...Using {n_folds}-fold CV for {model_name}...\")\n",
    "\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        y_pred = cross_val_predict(multi_model, X_train, y_train, cv=kf, n_jobs=n_jobs)\n",
    "\n",
    "        # Calculate macro F1-score for all labels\n",
    "        f1_macro = f1_score(y_train, y_pred, average='macro')\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"{model_name} Cross-Validation Macro F1: {f1_macro:.4f}\")\n",
    "        print(\"----------------------------\")\n",
    "\n",
    "        # Train on full data\n",
    "        multi_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Return both the full multi-model and the list of individual estimators\n",
    "        individual_models = multi_model.estimators_\n",
    "        \n",
    "        return multi_model, individual_models, y_pred, f1_macro\n",
    "\n",
    "    else:\n",
    "        print(f\"...No k-fold CV for {model_name}...\")\n",
    "        multi_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Return both the full multi-model and the list of individual estimators\n",
    "        individual_models = multi_model.estimators_\n",
    "        \n",
    "        return multi_model, individual_models\n",
    "\n",
    "def test_multilabel(models_list, X_test, Y_test, model_name, device=\"cuda\"):\n",
    "    print(f\"Testing {model_name} on {device}...\")\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    if device == 'cuda' and not torch.cuda.is_available():\n",
    "        print(\"Warning: CUDA requested but not available. Falling back to CPU.\")\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # Initialize prediction array\n",
    "    n_samples = X_test.shape[0]\n",
    "    n_outputs = len(models_list)\n",
    "    y_pred = np.zeros((n_samples, n_outputs), dtype=int)\n",
    "    \n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        print(f\"Using CUDA for prediction with {torch.cuda.device_count()} GPU(s).\")\n",
    "        \n",
    "        # For each estimator in the models list\n",
    "        for i, estimator in enumerate(models_list):\n",
    "            # Get the XGBoost booster\n",
    "            booster = estimator.get_booster()\n",
    "            \n",
    "            # Create DMatrix for this prediction\n",
    "            if isinstance(X_test, pd.DataFrame):\n",
    "                feature_names = X_test.columns.tolist()\n",
    "                X_test_dmatrix = xgb.DMatrix(X_test, feature_names=feature_names)\n",
    "            else:\n",
    "                X_test_dmatrix = xgb.DMatrix(X_test)\n",
    "            \n",
    "            # Make prediction - don't set predictor parameter here\n",
    "            pred_proba = booster.predict(X_test_dmatrix)\n",
    "            y_pred[:, i] = (pred_proba > 0.5).astype(int)\n",
    "    else:\n",
    "        # For CPU prediction, we need to construct predictions manually\n",
    "        for i, estimator in enumerate(models_list):\n",
    "            pred_proba = estimator.predict_proba(X_test)\n",
    "            y_pred[:, i] = (pred_proba[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_macro_test = f1_score(Y_test, y_pred, average='macro')\n",
    "    print(f\"Test Macro F1 score: {f1_macro_test:.4f}\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dc085-6fec-43d4-b943-b1ea6b9973bb",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c9aad6-2ce0-42a7-8bea-2aafc54dd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "output_dir = \"/gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def plot_classification_metrics(Y_test, y_pred, class_names, model_name=\"xgboost\"):\n",
    "    \"\"\"Plot and save classification metrics\"\"\"\n",
    "    # Initialize empty list for rows\n",
    "    rows = []\n",
    "    for idx, label in enumerate(class_names):\n",
    "        y_true_label = Y_test.iloc[:, idx]\n",
    "        y_pred_label = y_pred[:, idx]\n",
    "        rows.append({\n",
    "            'label': label,\n",
    "            'precision': precision_score(y_true_label, y_pred_label, zero_division=1),\n",
    "            'recall': recall_score(y_true_label, y_pred_label, zero_division=1),\n",
    "            'f1-score': f1_score(y_true_label, y_pred_label, zero_division=1),\n",
    "        })\n",
    "\n",
    "    # Create DataFrame\n",
    "    report_df = pd.DataFrame(rows).set_index('label')\n",
    "\n",
    "    # Add overall row\n",
    "    report_df.loc['overall'] = {\n",
    "        'precision': precision_score(Y_test, y_pred, average='weighted', zero_division=1),\n",
    "        'recall': recall_score(Y_test, y_pred, average='weighted', zero_division=1),\n",
    "        'f1-score': f1_score(Y_test, y_pred, average='weighted', zero_division=1),\n",
    "    }\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    csv_path = os.path.join(output_dir, f\"{model_name}_classification_metrics.csv\")\n",
    "    report_df.to_csv(csv_path)\n",
    "    print(f\"Saved classification metrics to: {csv_path}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = report_df.plot(kind='bar', figsize=(12, 6), colormap='viridis', edgecolor='black')\n",
    "    plt.title(\"Classification Metrics by Class (Including Overall)\", fontsize=14)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Metric', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_path = os.path.join(output_dir, f\"{model_name}_classification_metrics.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved classification metrics plot to: {plot_path}\")\n",
    "    \n",
    "    return report_df\n",
    "\n",
    "def plot_per_class_confusion_matrices(Y_test, y_pred, class_names, model_name=\"xgboost\"):\n",
    "    \"\"\"\n",
    "    Plots and saves a non-normalized confusion matrix per class (signature) for multilabel classification.\n",
    "    Outputs one plot per signature.\n",
    "    \"\"\"\n",
    "    mcm = multilabel_confusion_matrix(Y_test, y_pred)\n",
    "    \n",
    "    # Create a DataFrame to store confusion matrix data\n",
    "    cm_data = []\n",
    "\n",
    "    for i, cm in enumerate(mcm):\n",
    "        class_name = class_names[i].replace(' ', '_').replace('/', '_')\n",
    "        \n",
    "        # Store confusion matrix data\n",
    "        cm_data.append({\n",
    "            'class': class_names[i],\n",
    "            'true_neg': cm[0, 0],\n",
    "            'false_pos': cm[0, 1],\n",
    "            'false_neg': cm[1, 0],\n",
    "            'true_pos': cm[1, 1]\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(4, 4))\n",
    "        ax = sns.heatmap(\n",
    "            cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Pred 0\", \"Pred 1\"], yticklabels=[\"True 0\", \"True 1\"]\n",
    "        )\n",
    "        ax.set_title(f\"Confusion Matrix for {class_names[i]}\")\n",
    "        ax.set_xlabel(\"Predicted Label\")\n",
    "        ax.set_ylabel(\"True Label\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = os.path.join(output_dir, f\"{model_name}_confusion_matrix_{class_name}.png\")\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved confusion matrix for {class_names[i]} to: {plot_path}\")\n",
    "    \n",
    "    # Save confusion matrix data to CSV\n",
    "    cm_df = pd.DataFrame(cm_data)\n",
    "    csv_path = os.path.join(output_dir, f\"{model_name}_confusion_matrices.csv\")\n",
    "    cm_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved confusion matrix data to: {csv_path}\")\n",
    "    \n",
    "    return cm_df\n",
    "\n",
    "def plot_save_shap_values(models_list, X_test, feature_names=None, class_names=None, \n",
    "                         max_display=10, sample_size=100, seed=9, model_name=\"xgboost\"):\n",
    "    \"\"\"\n",
    "    Generate and save SHAP plots for multiple models in a MultiOutputClassifier.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models_list : list\n",
    "        List of trained XGBoost models from MultiOutputClassifier\n",
    "    X_test : DataFrame or ndarray\n",
    "        Test data for SHAP value calculation\n",
    "    feature_names : list, optional\n",
    "        Names of the features\n",
    "    class_names : list, optional\n",
    "        Names of the target classes/labels\n",
    "    max_display : int, optional\n",
    "        Maximum number of features to display in summary plots\n",
    "    sample_size : int, optional\n",
    "        Number of samples to use for SHAP value calculation (for large datasets)\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility when sampling\n",
    "    model_name : str, optional\n",
    "        Name of the model for file naming\n",
    "    \"\"\"\n",
    "    # Convert pandas DataFrame to numpy if needed\n",
    "    if hasattr(X_test, 'values'):\n",
    "        if feature_names is None:\n",
    "            feature_names = X_test.columns.tolist()\n",
    "        X_test_values = X_test.values\n",
    "    else:\n",
    "        X_test_values = X_test\n",
    "        \n",
    "    # If we have too many samples, use a subset\n",
    "    if sample_size and X_test_values.shape[0] > sample_size:\n",
    "        np.random.seed(seed)  # Using the provided seed parameter\n",
    "        sample_idx = np.random.choice(X_test_values.shape[0], sample_size, replace=False)\n",
    "        X_test_sample = X_test_values[sample_idx]\n",
    "    else:\n",
    "        X_test_sample = X_test_values\n",
    "    \n",
    "    # Define class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class_{i}\" for i in range(len(models_list))]\n",
    "    \n",
    "    # Create DataFrame to store SHAP values\n",
    "    all_shap_values = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each model (one per target class)\n",
    "    for i, model in enumerate(models_list):\n",
    "        class_name = class_names[i].replace(' ', '_').replace('/', '_')\n",
    "        print(f\"\\nGenerating SHAP plots for {class_names[i]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize SHAP explainer\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            \n",
    "            # Calculate SHAP values\n",
    "            shap_values = explainer.shap_values(X_test_sample)\n",
    "            \n",
    "            # For XGBoost binary classifiers, we might get a list of arrays\n",
    "            if isinstance(shap_values, list):\n",
    "                # For binary classification, we take the second class (positive class)\n",
    "                shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "            \n",
    "            # Calculate mean absolute SHAP value for each feature\n",
    "            mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "            \n",
    "            # Create DataFrame for this class\n",
    "            shap_df = pd.DataFrame({\n",
    "                'Feature': feature_names if feature_names else [f\"Feature_{j}\" for j in range(len(mean_abs_shap))],\n",
    "                'Mean_Abs_SHAP': mean_abs_shap,\n",
    "                'Class': class_names[i]\n",
    "            })\n",
    "            shap_df = shap_df.sort_values('Mean_Abs_SHAP', ascending=False)\n",
    "            \n",
    "            # Add to collection\n",
    "            all_shap_values = pd.concat([all_shap_values, shap_df])\n",
    "            \n",
    "            # Plot SHAP summary\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            shap.summary_plot(\n",
    "                shap_values, \n",
    "                X_test_sample, \n",
    "                feature_names=feature_names,\n",
    "                max_display=max_display,\n",
    "                show=False\n",
    "            )\n",
    "            # Simplify x-axis title\n",
    "            plt.xlabel(\"SHAP value\", fontsize=10)\n",
    "            plt.title(f\"SHAP Feature Importance for {class_names[i]}\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save plot\n",
    "            plot_path = os.path.join(output_dir, f\"{model_name}_shap_summary_{class_name}.png\")\n",
    "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved SHAP summary plot to: {plot_path}\")\n",
    "            \n",
    "            # Plot SHAP bar summary (average absolute SHAP values)\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            shap.summary_plot(\n",
    "                shap_values, \n",
    "                X_test_sample, \n",
    "                feature_names=feature_names,\n",
    "                plot_type=\"bar\",\n",
    "                max_display=max_display,\n",
    "                show=False\n",
    "            )\n",
    "            # Simplify x-axis title\n",
    "            plt.xlabel(\"mean(|SHAP value|)\", fontsize=10)\n",
    "            plt.title(f\"SHAP Mean Impact for {class_names[i]}\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save plot\n",
    "            plot_path = os.path.join(output_dir, f\"{model_name}_shap_bar_{class_name}.png\")\n",
    "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved SHAP bar plot to: {plot_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating SHAP plots for {class_names[i]}: {str(e)}\")\n",
    "    \n",
    "    # Save all SHAP values to CSV\n",
    "    csv_path = os.path.join(output_dir, f\"{model_name}_shap_values.csv\")\n",
    "    all_shap_values.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved SHAP values to: {csv_path}\")\n",
    "    \n",
    "    return all_shap_values\n",
    "\n",
    "def plot_save_xgb_feature_importance(models_list, feature_names=None, class_names=None, \n",
    "                                    top_n=10, figsize=(6, 4), importance_type='total_gain',\n",
    "                                    model_name=\"xgboost\"):\n",
    "    \"\"\"\n",
    "    Plot and save feature importance for each model in the MultiOutputClassifier.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models_list : list\n",
    "        List of trained XGBoost models from MultiOutputClassifier\n",
    "    feature_names : list, optional\n",
    "        Names of the features\n",
    "    class_names : list, optional\n",
    "        Names of the target classes/labels\n",
    "    top_n : int, optional\n",
    "        Number of top features to display\n",
    "    figsize : tuple, optional\n",
    "        Size of the figure\n",
    "    importance_type : str, optional\n",
    "        Type of importance to plot ('total_gain', 'gain', 'weight', 'total_cover', 'cover')\n",
    "    model_name : str, optional\n",
    "        Name of the model for file naming\n",
    "    \"\"\"\n",
    "    # Define class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class_{i}\" for i in range(len(models_list))]\n",
    "    \n",
    "    # Create DataFrame to store all importance scores\n",
    "    all_importance = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each model (one per target class)\n",
    "    for i, model in enumerate(models_list):\n",
    "        class_name = class_names[i].replace(' ', '_').replace('/', '_')\n",
    "        \n",
    "        # Get the booster from the model\n",
    "        booster = model.get_booster()\n",
    "        \n",
    "        # Get feature importance based on specified type\n",
    "        importance_scores = booster.get_score(importance_type=importance_type)\n",
    "        \n",
    "        # Convert to dataframe for easier handling\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': list(importance_scores.keys()),\n",
    "            'Importance': list(importance_scores.values()),\n",
    "            'Class': class_names[i]\n",
    "        })\n",
    "        \n",
    "        # Add to collection\n",
    "        all_importance = pd.concat([all_importance, importance_df])\n",
    "        \n",
    "        # Sort by importance (descending)\n",
    "        plot_df = importance_df.sort_values('Importance', ascending=False).head(top_n).iloc[::-1]\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.title(f\"Feature Importance for {class_names[i]}\", fontsize=12)\n",
    "        plt.barh(range(len(plot_df)), plot_df['Importance'], align='center')\n",
    "        \n",
    "        # Add feature names to y-axis\n",
    "        plt.yticks(range(len(plot_df)), plot_df['Feature'])\n",
    "        \n",
    "        plt.xlabel(f'Importance ({importance_type})')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = os.path.join(output_dir, f\"{model_name}_xgb_importance_{class_name}.png\")\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved XGBoost feature importance plot to: {plot_path}\")\n",
    "    \n",
    "    # Save all importance values to CSV\n",
    "    csv_path = os.path.join(output_dir, f\"{model_name}_xgb_feature_importance.csv\")\n",
    "    all_importance.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved XGBoost feature importance to: {csv_path}\")\n",
    "    \n",
    "    return all_importance\n",
    "\n",
    "# Combined function to run all analyses\n",
    "def analyze_and_save_model_results(models_list, X_test, Y_test, y_pred, \n",
    "                                  feature_names=None, class_names=None,\n",
    "                                  top_n=10, sample_size=100, model_name=\"xgboost\"):\n",
    "    \"\"\"\n",
    "    Run and save all analyses for the model in one go.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models_list : list\n",
    "        List of trained XGBoost models from MultiOutputClassifier\n",
    "    X_test : DataFrame or ndarray\n",
    "        Test data\n",
    "    Y_test : DataFrame or ndarray\n",
    "        True labels\n",
    "    y_pred : ndarray\n",
    "        Predicted labels\n",
    "    feature_names : list, optional\n",
    "        Names of the features\n",
    "    class_names : list, optional\n",
    "        Names of the target classes/labels\n",
    "    top_n : int, optional\n",
    "        Number of top features to display\n",
    "    sample_size : int, optional\n",
    "        Number of samples to use for SHAP analysis\n",
    "    model_name : str, optional\n",
    "        Name of the model for file naming\n",
    "    \"\"\"\n",
    "    print(f\"\\n==== Saving All Results to: {output_dir} ====\\n\")\n",
    "    \n",
    "    # Extract feature names if available\n",
    "    if feature_names is None and hasattr(X_test, 'columns'):\n",
    "        feature_names = X_test.columns.tolist()\n",
    "    \n",
    "    # Extract class names if available\n",
    "    if class_names is None and hasattr(Y_test, 'columns'):\n",
    "        class_names = Y_test.columns.tolist()\n",
    "    elif class_names is None:\n",
    "        class_names = [f\"Class_{i}\" for i in range(Y_test.shape[1])]\n",
    "    \n",
    "    # 1. Classification metrics\n",
    "    print(\"\\n==== Plotting Classification Metrics ====\")\n",
    "    metrics_df = plot_classification_metrics(Y_test, y_pred, class_names, model_name)\n",
    "    \n",
    "    # 2. Confusion matrices\n",
    "    print(\"\\n==== Plotting Confusion Matrices ====\")\n",
    "    cm_df = plot_per_class_confusion_matrices(Y_test, y_pred, class_names, model_name)\n",
    "    \n",
    "    # 3. XGBoost Feature Importance\n",
    "    print(\"\\n==== Plotting XGBoost Feature Importance ====\")\n",
    "    xgb_importance = plot_save_xgb_feature_importance(\n",
    "        models_list, \n",
    "        feature_names, \n",
    "        class_names, \n",
    "        top_n=top_n, \n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # 4. SHAP Analysis\n",
    "    print(\"\\n==== Plotting SHAP Analysis ====\")\n",
    "    shap_values = plot_save_shap_values(\n",
    "        models_list, \n",
    "        X_test, \n",
    "        feature_names, \n",
    "        class_names, \n",
    "        max_display=top_n,\n",
    "        sample_size=sample_size,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n==== Analysis Complete! All results saved to: {output_dir} ====\")\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics_df,\n",
    "        'confusion_matrices': cm_df,\n",
    "        'xgb_importance': xgb_importance,\n",
    "        'shap_values': shap_values\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa48e4-12fc-4e38-8678-ea8d48175137",
   "metadata": {},
   "source": [
    "# Prediction pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a0937-2bd6-464b-b098-a65058b69d11",
   "metadata": {},
   "source": [
    "## c6_top1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acab8a9f-3847-42dd-ade4-b13ddf4d84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1420, 28)\n",
      "(356, 28)\n",
      "(1420, 13)\n",
      "(356, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "model_name = \"c6_top1000\"\n",
    "X_train = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/c6_top1000/splits/pangyn_X_train.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/c6_top1000/splits/pangyn_X_test.csv\", index_col=0)\n",
    "Y_train = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/c6_top1000/splits/pangyn_Y_train.csv\", index_col=0)\n",
    "Y_test = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/c6_top1000/splits/pangyn_Y_test.csv\", index_col=0)\n",
    "\n",
    "Y_cols_drop = ['SBS36', 'SBS34', 'SBS10a', 'SBS35', 'SBS31', 'SBS28', 'SBS98', 'SBS10b', 'SBS97', 'SBS96', 'SBS8', 'SBS26', 'SBS51', 'SBS54', 'SBS60']\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_train.drop(columns=Y_cols_drop, inplace=True)\n",
    "Y_test.drop(columns=Y_cols_drop, inplace=True)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_train = (Y_train > 0).astype(int)\n",
    "Y_test = (Y_test > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1442799-29fb-4014-b4e9-e675d851fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MultiOutputClassifier (XGBClassifier) on c6_top1000...\n",
      "\n",
      "c6_top1000 parameters:\n",
      "{\n",
      "  \"objective\": \"binary:logistic\",\n",
      "  \"base_score\": null,\n",
      "  \"booster\": null,\n",
      "  \"callbacks\": null,\n",
      "  \"colsample_bylevel\": null,\n",
      "  \"colsample_bynode\": null,\n",
      "  \"colsample_bytree\": null,\n",
      "  \"device\": \"cuda\",\n",
      "  \"early_stopping_rounds\": null,\n",
      "  \"enable_categorical\": false,\n",
      "  \"eval_metric\": \"logloss\",\n",
      "  \"feature_types\": null,\n",
      "  \"gamma\": null,\n",
      "  \"grow_policy\": null,\n",
      "  \"importance_type\": null,\n",
      "  \"interaction_constraints\": null,\n",
      "  \"learning_rate\": 0.05,\n",
      "  \"max_bin\": null,\n",
      "  \"max_cat_threshold\": null,\n",
      "  \"max_cat_to_onehot\": null,\n",
      "  \"max_delta_step\": null,\n",
      "  \"max_depth\": 5,\n",
      "  \"max_leaves\": null,\n",
      "  \"min_child_weight\": null,\n",
      "  \"missing\": NaN,\n",
      "  \"monotone_constraints\": null,\n",
      "  \"multi_strategy\": null,\n",
      "  \"n_estimators\": 700,\n",
      "  \"n_jobs\": null,\n",
      "  \"num_parallel_tree\": null,\n",
      "  \"random_state\": 9,\n",
      "  \"reg_alpha\": null,\n",
      "  \"reg_lambda\": null,\n",
      "  \"sampling_method\": null,\n",
      "  \"scale_pos_weight\": null,\n",
      "  \"subsample\": null,\n",
      "  \"tree_method\": \"hist\",\n",
      "  \"validate_parameters\": null,\n",
      "  \"verbosity\": null\n",
      "}\n",
      "...No k-fold CV for c6_top1000...\n",
      "Testing c6_top1000 on cuda...\n",
      "Using CUDA for prediction with 1 GPU(s).\n",
      "Test Macro F1 score: 0.8461\n"
     ]
    }
   ],
   "source": [
    "params_dict = {\n",
    "    \"n_estimators\": 700,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"random_state\": 9,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"device\":\"cuda\"\n",
    "}\n",
    "\n",
    "# Run the training function (without k-fold for now)\n",
    "model, models_list = train_val_multilabel(\n",
    "    model_name=model_name, \n",
    "    X_train=X_train, \n",
    "    y_train=Y_train, \n",
    "    kfold=False,  # No k-fold, training on full data\n",
    "    params_dict=params_dict,\n",
    "    print_params=True\n",
    ")\n",
    "\n",
    "# Use the individual models list for prediction to properly handle GPU prediction\n",
    "y_pred = test_multilabel(models_list, X_test, Y_test, model_name, device=\"cuda\")\n",
    "\n",
    "# Get your feature names (column names from your training data)\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Get your class names (the target variables you're predicting)\n",
    "class_names = Y_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fcb047-c49e-46b7-8f33-95ef6cdb7a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Saving All Results to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier ====\n",
      "\n",
      "\n",
      "==== Plotting Classification Metrics ====\n",
      "Saved classification metrics to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_classification_metrics.csv\n",
      "Saved classification metrics plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_classification_metrics.png\n",
      "\n",
      "==== Plotting Confusion Matrices ====\n",
      "Saved confusion matrix for SBS1 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS1.png\n",
      "Saved confusion matrix for SBS10d to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS10d.png\n",
      "Saved confusion matrix for SBS13 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS13.png\n",
      "Saved confusion matrix for SBS14 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS14.png\n",
      "Saved confusion matrix for SBS15 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS15.png\n",
      "Saved confusion matrix for SBS18 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS18.png\n",
      "Saved confusion matrix for SBS2 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS2.png\n",
      "Saved confusion matrix for SBS20 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS20.png\n",
      "Saved confusion matrix for SBS21 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS21.png\n",
      "Saved confusion matrix for SBS5 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS5.png\n",
      "Saved confusion matrix for SBS3 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS3.png\n",
      "Saved confusion matrix for SBS100 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS100.png\n",
      "Saved confusion matrix for SBS17a to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrix_SBS17a.png\n",
      "Saved confusion matrix data to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_confusion_matrices.csv\n",
      "\n",
      "==== Plotting XGBoost Feature Importance ====\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS1.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS10d.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS13.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS14.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS15.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS18.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS2.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS20.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS21.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS5.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS3.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS100.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_importance_SBS17a.png\n",
      "Saved XGBoost feature importance to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_xgb_feature_importance.csv\n",
      "\n",
      "==== Plotting SHAP Analysis ====\n",
      "\n",
      "Generating SHAP plots for SBS1...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS1.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS1.png\n",
      "\n",
      "Generating SHAP plots for SBS10d...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS10d.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS10d.png\n",
      "\n",
      "Generating SHAP plots for SBS13...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS13.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS13.png\n",
      "\n",
      "Generating SHAP plots for SBS14...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS14.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS14.png\n",
      "\n",
      "Generating SHAP plots for SBS15...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS15.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS15.png\n",
      "\n",
      "Generating SHAP plots for SBS18...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS18.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS18.png\n",
      "\n",
      "Generating SHAP plots for SBS2...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS2.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS2.png\n",
      "\n",
      "Generating SHAP plots for SBS20...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS20.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS20.png\n",
      "\n",
      "Generating SHAP plots for SBS21...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS21.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS21.png\n",
      "\n",
      "Generating SHAP plots for SBS5...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS5.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS5.png\n",
      "\n",
      "Generating SHAP plots for SBS3...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS3.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS3.png\n",
      "\n",
      "Generating SHAP plots for SBS100...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS100.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS100.png\n",
      "\n",
      "Generating SHAP plots for SBS17a...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_summary_SBS17a.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_bar_SBS17a.png\n",
      "Saved SHAP values to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/c6_top1000_shap_values.csv\n",
      "\n",
      "==== Analysis Complete! All results saved to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier ====\n",
      "All plots and data have been saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the comprehensive analysis and save everything\n",
    "results = analyze_and_save_model_results(\n",
    "    models_list=models_list,\n",
    "    X_test=X_test,\n",
    "    Y_test=Y_test,\n",
    "    y_pred=y_pred,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    top_n=10,              # Display only top 10 features\n",
    "    sample_size=100,       # Use 100 samples for SHAP analysis\n",
    "    model_name=model_name  # Customize model name for filenames\n",
    ")\n",
    "\n",
    "print(\"All plots and data have been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83c9a5-6c60-415d-b3b5-3a09c2f520c5",
   "metadata": {},
   "source": [
    "## l1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bdcdd5-e7b1-4ca8-be4f-33b5324003bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1420, 28)\n",
      "(356, 28)\n",
      "(1420, 13)\n",
      "(356, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "model_name = \"l1000\"\n",
    "X_train = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/l1000/splits/pangyn_X_train.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/l1000/splits/pangyn_X_test.csv\", index_col=0)\n",
    "Y_train = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/l1000/splits/pangyn_Y_train.csv\", index_col=0)\n",
    "Y_test = pd.read_csv(\"/gpfs/data/courses/aio2025/yb2612/data/rna2sig/l1000/splits/pangyn_Y_test.csv\", index_col=0)\n",
    "\n",
    "Y_cols_drop = ['SBS36', 'SBS34', 'SBS10a', 'SBS35', 'SBS31', 'SBS28', 'SBS98', 'SBS10b', 'SBS97', 'SBS96', 'SBS8', 'SBS26', 'SBS51', 'SBS54', 'SBS60']\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_train.drop(columns=Y_cols_drop, inplace=True)\n",
    "Y_test.drop(columns=Y_cols_drop, inplace=True)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_train = (Y_train > 0).astype(int)\n",
    "Y_test = (Y_test > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c9a206-719d-41b3-968a-79cf4eaa28fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MultiOutputClassifier (XGBClassifier) on l1000...\n",
      "\n",
      "l1000 parameters:\n",
      "{\n",
      "  \"objective\": \"binary:logistic\",\n",
      "  \"base_score\": null,\n",
      "  \"booster\": null,\n",
      "  \"callbacks\": null,\n",
      "  \"colsample_bylevel\": null,\n",
      "  \"colsample_bynode\": null,\n",
      "  \"colsample_bytree\": null,\n",
      "  \"device\": \"cuda\",\n",
      "  \"early_stopping_rounds\": null,\n",
      "  \"enable_categorical\": false,\n",
      "  \"eval_metric\": \"logloss\",\n",
      "  \"feature_types\": null,\n",
      "  \"gamma\": null,\n",
      "  \"grow_policy\": null,\n",
      "  \"importance_type\": null,\n",
      "  \"interaction_constraints\": null,\n",
      "  \"learning_rate\": 0.05,\n",
      "  \"max_bin\": null,\n",
      "  \"max_cat_threshold\": null,\n",
      "  \"max_cat_to_onehot\": null,\n",
      "  \"max_delta_step\": null,\n",
      "  \"max_depth\": 5,\n",
      "  \"max_leaves\": null,\n",
      "  \"min_child_weight\": null,\n",
      "  \"missing\": NaN,\n",
      "  \"monotone_constraints\": null,\n",
      "  \"multi_strategy\": null,\n",
      "  \"n_estimators\": 700,\n",
      "  \"n_jobs\": null,\n",
      "  \"num_parallel_tree\": null,\n",
      "  \"random_state\": 9,\n",
      "  \"reg_alpha\": null,\n",
      "  \"reg_lambda\": null,\n",
      "  \"sampling_method\": null,\n",
      "  \"scale_pos_weight\": null,\n",
      "  \"subsample\": null,\n",
      "  \"tree_method\": \"hist\",\n",
      "  \"validate_parameters\": null,\n",
      "  \"verbosity\": null\n",
      "}\n",
      "...No k-fold CV for l1000...\n",
      "Testing l1000 on cuda...\n",
      "Using CUDA for prediction with 1 GPU(s).\n",
      "Test Macro F1 score: 0.8385\n"
     ]
    }
   ],
   "source": [
    "params_dict = {\n",
    "    \"n_estimators\": 700,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"random_state\": 9,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"device\":\"cuda\"\n",
    "}\n",
    "\n",
    "# Run the training function (without k-fold for now)\n",
    "model, models_list = train_val_multilabel(\n",
    "    model_name=model_name, \n",
    "    X_train=X_train, \n",
    "    y_train=Y_train, \n",
    "    kfold=False,  # No k-fold, training on full data\n",
    "    params_dict=params_dict,\n",
    "    print_params=True\n",
    ")\n",
    "\n",
    "# Use the individual models list for prediction to properly handle GPU prediction\n",
    "y_pred = test_multilabel(models_list, X_test, Y_test, model_name, device=\"cuda\")\n",
    "\n",
    "# Get your feature names (column names from your training data)\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Get your class names (the target variables you're predicting)\n",
    "class_names = Y_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5c0a27-98f6-4dee-a82b-7fb287a79b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Saving All Results to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier ====\n",
      "\n",
      "\n",
      "==== Plotting Classification Metrics ====\n",
      "Saved classification metrics to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_classification_metrics.csv\n",
      "Saved classification metrics plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_classification_metrics.png\n",
      "\n",
      "==== Plotting Confusion Matrices ====\n",
      "Saved confusion matrix for SBS1 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS1.png\n",
      "Saved confusion matrix for SBS10d to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS10d.png\n",
      "Saved confusion matrix for SBS13 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS13.png\n",
      "Saved confusion matrix for SBS14 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS14.png\n",
      "Saved confusion matrix for SBS15 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS15.png\n",
      "Saved confusion matrix for SBS18 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS18.png\n",
      "Saved confusion matrix for SBS2 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS2.png\n",
      "Saved confusion matrix for SBS20 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS20.png\n",
      "Saved confusion matrix for SBS21 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS21.png\n",
      "Saved confusion matrix for SBS5 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS5.png\n",
      "Saved confusion matrix for SBS3 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS3.png\n",
      "Saved confusion matrix for SBS100 to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS100.png\n",
      "Saved confusion matrix for SBS17a to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrix_SBS17a.png\n",
      "Saved confusion matrix data to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_confusion_matrices.csv\n",
      "\n",
      "==== Plotting XGBoost Feature Importance ====\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS1.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS10d.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS13.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS14.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS15.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS18.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS2.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS20.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS21.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS5.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS3.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS100.png\n",
      "Saved XGBoost feature importance plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_importance_SBS17a.png\n",
      "Saved XGBoost feature importance to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_xgb_feature_importance.csv\n",
      "\n",
      "==== Plotting SHAP Analysis ====\n",
      "\n",
      "Generating SHAP plots for SBS1...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS1.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS1.png\n",
      "\n",
      "Generating SHAP plots for SBS10d...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS10d.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS10d.png\n",
      "\n",
      "Generating SHAP plots for SBS13...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS13.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS13.png\n",
      "\n",
      "Generating SHAP plots for SBS14...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS14.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS14.png\n",
      "\n",
      "Generating SHAP plots for SBS15...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS15.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS15.png\n",
      "\n",
      "Generating SHAP plots for SBS18...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS18.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS18.png\n",
      "\n",
      "Generating SHAP plots for SBS2...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS2.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS2.png\n",
      "\n",
      "Generating SHAP plots for SBS20...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS20.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS20.png\n",
      "\n",
      "Generating SHAP plots for SBS21...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS21.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS21.png\n",
      "\n",
      "Generating SHAP plots for SBS5...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS5.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS5.png\n",
      "\n",
      "Generating SHAP plots for SBS3...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS3.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS3.png\n",
      "\n",
      "Generating SHAP plots for SBS100...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS100.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS100.png\n",
      "\n",
      "Generating SHAP plots for SBS17a...\n",
      "Saved SHAP summary plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_summary_SBS17a.png\n",
      "Saved SHAP bar plot to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_bar_SBS17a.png\n",
      "Saved SHAP values to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier/l1000_shap_values.csv\n",
      "\n",
      "==== Analysis Complete! All results saved to: /gpfs/home/yb2612/aio2025/yb2612/results/rec2sig/classifier ====\n",
      "All plots and data have been saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the comprehensive analysis and save everything\n",
    "results = analyze_and_save_model_results(\n",
    "    models_list=models_list,\n",
    "    X_test=X_test,\n",
    "    Y_test=Y_test,\n",
    "    y_pred=y_pred,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    top_n=10,              # Display only top 10 features\n",
    "    sample_size=100,       # Use 100 samples for SHAP analysis\n",
    "    model_name=model_name  # Customize model name for filenames\n",
    ")\n",
    "\n",
    "print(\"All plots and data have been saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-py-env",
   "language": "python",
   "name": "my-py-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
